{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MULTIPLIER = 50\n",
    "COMMISSION = 0.85\n",
    "TRAIN = 'TRAIN'\n",
    "TEST = 'TEST'\n",
    "TRAIN_PICKLE = 'TRAIN_PICKLE.pickle'\n",
    "TEST_PICKLE = 'TEST_PICKLE.pickle'\n",
    "TRAIN_DIR = 'TRAIN DATA/*.csv'\n",
    "TEST_DIR = 'TEST DATA/*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set to False if your serialized file has not yet been generated\n",
    "# Remember to change back to \"True\" once the serialized file has been generated\n",
    "DATA_SERIALIZED = True\n",
    "\n",
    "if not DATA_SERIALIZED:\n",
    "    \n",
    "    # Writing files to pickle\n",
    "    train_files = glob.glob(TRAIN_DIR)\n",
    "    test_files = glob.glob(TEST_DIR)\n",
    "    train_files.sort()\n",
    "    test_files.sort()\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    for filename in train_files:\n",
    "        train_list.append(pd.read_csv(filename, index_col=0))\n",
    "    for filename in test_files:\n",
    "        test_list.append(pd.read_csv(filename, index_col=0))\n",
    "    train = pd.concat(train_list)\n",
    "    test = pd.concat(test_list)\n",
    "    train.to_pickle(TRAIN_PICKLE)\n",
    "    test.to_pickle(TEST_PICKLE)\n",
    "    \n",
    "    # Garbage collection\n",
    "    del(train_files)\n",
    "    del(test_files)\n",
    "    del(train_list)\n",
    "    del(test_list)\n",
    "    del(train)\n",
    "    del(test)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(TRAIN_PICKLE)\n",
    "test_data = pd.read_pickle(TEST_PICKLE)\n",
    "train_data.index = pd.to_datetime(train_data.index)\n",
    "test_data.index = pd.to_datetime(test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterData (data, columns):\n",
    "    toReturn = data.loc[data['eB'] > 0, :] # Filter out no data rows\n",
    "    return toReturn.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def winning_probability (pnls):\n",
    "    if len(pnls) == 0:\n",
    "        return np.nan\n",
    "    positive = 0\n",
    "    for pnl in pnls:\n",
    "        if pnl > 0:\n",
    "            positive += 1\n",
    "    return positive / len(pnls)\n",
    "\n",
    "def reward_to_risk_ratio (pnls):\n",
    "    if len(pnls) == 0:\n",
    "        return np.nan\n",
    "    wins = []\n",
    "    losses = []\n",
    "    for pnl in pnls:\n",
    "        if pnl > 0:\n",
    "            wins.append(pnl)\n",
    "        else:\n",
    "            losses.append(pnl)\n",
    "    return np.mean(wins) / abs(np.mean(losses))\n",
    "\n",
    "def t_stat (pnls):\n",
    "    if len(pnls) == 0:\n",
    "        return np.nan\n",
    "    return np.sqrt(len(pnls)) * (np.mean(pnls) / np.std(pnls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_rsi_data (data, mode) :\n",
    "    if mode == 'TRAIN':\n",
    "        rsi_data = filterData(data, TRAIN_START_DATE, TRAIN_END_DATE, ['eB', 'eA'])\n",
    "    else:\n",
    "        rsi_data = filterData(data, TEST_START_DATE, TEST_END_DATE, ['eB', 'eA'])\n",
    "    rsi_data.rename(index=str, columns={'eB': \"bid\", \"eA\": \"ask\"}, inplace=True)\n",
    "    rsi_data['mid'] = rsi_data[['bid', 'ask']].mean(axis=1)\n",
    "    rsi_data['change'] = (rsi_data.mid - rsi_data.shift(1).mid)\n",
    "    rsi_data = rsi_data.iloc[1:, :]\n",
    "    rsi_data['gain'] = rsi_data['change'].apply(lambda x: x if x > 0 else 0)\n",
    "    rsi_data['loss'] = rsi_data['change'].apply(lambda x: -x if x < 0 else 0)\n",
    "    return rsi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PERIODS = [1,3, 5, 10, 15, 30, 60, 90, 120, 180, 330, 660]\n",
    "LOOK_BACK = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model (days, period, mode):\n",
    "        \n",
    "    # Varying the period of the RSI\n",
    "    PERIOD = days * period\n",
    "\n",
    "    # Prepare initial data table for manipulation\n",
    "    rsi_data = init_rsi_data(data, mode)\n",
    "\n",
    "    # Calculate RS and RSI based on varied period\n",
    "    rsi_data['rs'] = rsi_data['gain'].rolling(window=PERIOD).mean() / rsi_data['loss'].rolling(window=PERIOD).mean()\n",
    "    rsi_data['rsi'] = 100 - 100 / (1 + rsi_data['rs'])\n",
    "\n",
    "    # Generate signals\n",
    "    rsi_data['signal'] = rsi_data['rsi'].apply(lambda x: 1 if x > UPPER_BOUND else (-1 if x < LOWER_BOUND else 0))\n",
    "    signal_data = rsi_data.loc[rsi_data['signal'] != 0, :]\n",
    "    signal = 0\n",
    "    indices = []\n",
    "    for (index, value) in signal_data.iterrows():\n",
    "        if signal != value.signal:\n",
    "            signal = value.signal\n",
    "            indices.append(index)\n",
    "    if len(indices) % 2 != 0:\n",
    "        indices.pop()\n",
    "\n",
    "    # Consolidate price data and signals into transactions column\n",
    "    trading_data = signal_data.loc[indices, :]\n",
    "    if trading_data.shape[0] == 0: \n",
    "        # Corner case caught for empty signal data table\n",
    "        trading_data['transaction'] = pd.Series()\n",
    "    else:\n",
    "        trading_data['transaction'] = trading_data.apply(lambda x: x.ask * -1 if x.signal > 0 else x.bid, axis=1)\n",
    "\n",
    "    # Calculate PNLs from transactions, inclusive of commission and multiplier\n",
    "    pnl_list = []\n",
    "    transactions = list(trading_data['transaction'])\n",
    "    for i in range(0, len(transactions), 2):\n",
    "        pnl = (transactions[i] + transactions[i + 1]) * MULTIPLIER - 2 * COMMISSION\n",
    "        pnl_list.append(pnl)\n",
    "\n",
    "    # Calculate performance\n",
    "    wp = winning_probability(pnl_list)\n",
    "    rrr= reward_to_risk_ratio(pnl_list)\n",
    "    ts = t_stat(pnl_list)\n",
    "    total_pnl = sum(pnl_list)\n",
    "\n",
    "    print (f'Periods: [{ period }], Look-back Days: [{ days }], Winning Probability: [{ wp }], Reward-to-Risk Ratio: [{ rrr }], T-Stat: [{ ts }], Total PNL: [{ total_pnl }]')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for period in PERIODS:\n",
    "    for days in LOOK_BACK:\n",
    "        model(days, period, TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters chosen based on highest t-statistic\n",
    "model(90, 60, TEST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
