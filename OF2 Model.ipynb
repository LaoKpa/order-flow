{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Gamma - CME Mini S&P (ES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MULTIPLIER = 50\n",
    "COMMISSION = 0.85\n",
    "TRAIN = 'TRAIN'\n",
    "TEST = 'TEST'\n",
    "TRAIN_PICKLE = 'TRAIN_PICKLE.pickle'\n",
    "TEST_PICKLE = 'TEST_PICKLE.pickle'\n",
    "TRAIN_DIR = 'TRAIN DATA/*.csv'\n",
    "TEST_DIR = 'TEST DATA/*.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set to False if your serialized file has not yet been generated\n",
    "# Remember to change back to \"True\" once the serialized file has been generated\n",
    "DATA_SERIALIZED = True\n",
    "\n",
    "if not DATA_SERIALIZED:\n",
    "    \n",
    "    # Writing files to pickle\n",
    "    train_files = glob.glob(TRAIN_DIR)\n",
    "    test_files = glob.glob(TEST_DIR)\n",
    "    train_files.sort()\n",
    "    test_files.sort()\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    for filename in train_files:\n",
    "        train_list.append(pd.read_csv(filename, index_col=0))\n",
    "    for filename in test_files:\n",
    "        test_list.append(pd.read_csv(filename, index_col=0))\n",
    "    train = pd.concat(train_list)\n",
    "    test = pd.concat(test_list)\n",
    "    train.to_pickle(TRAIN_PICKLE)\n",
    "    test.to_pickle(TEST_PICKLE)\n",
    "    \n",
    "    # Garbage collection\n",
    "    del(train_files)\n",
    "    del(test_files)\n",
    "    del(train_list)\n",
    "    del(test_list)\n",
    "    del(train)\n",
    "    del(test)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(TRAIN_PICKLE)\n",
    "test_data = pd.read_pickle(TEST_PICKLE)\n",
    "train_data.index = pd.to_datetime(train_data.index)\n",
    "test_data.index = pd.to_datetime(test_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterData (data, columns):\n",
    "    toReturn = data.loc[data['eB'] > 0, :] # Filter out no data rows\n",
    "    return toReturn.loc[:, columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def winning_probability (pnls):\n",
    "    if len(pnls) == 0:\n",
    "        return np.nan\n",
    "    positive = 0\n",
    "    for pnl in pnls:\n",
    "        if pnl > 0:\n",
    "            positive += 1\n",
    "    return positive / len(pnls)\n",
    "\n",
    "def reward_to_risk_ratio (pnls):\n",
    "    if len(pnls) == 0:\n",
    "        return np.nan\n",
    "    wins = []\n",
    "    losses = []\n",
    "    for pnl in pnls:\n",
    "        if pnl > 0:\n",
    "            wins.append(pnl)\n",
    "        else:\n",
    "            losses.append(pnl)\n",
    "    return np.mean(wins) / abs(np.mean(losses))\n",
    "\n",
    "def t_stat (pnls):\n",
    "    if len(pnls) == 0:\n",
    "        return np.nan\n",
    "    return np.sqrt(len(pnls)) * (np.mean(pnls) / np.std(pnls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Flow Model (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OF2_COLUMNS = ['eB', 'eA', 'V', 'OF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_of2_data (data):\n",
    "    df = filterData(data, OF2_COLUMNS)\n",
    "    df.rename(index=str, columns={'eB':'bid','eA':'ask','V':'volume','OF':'orderFlow'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TICK_SIZE = 0.25\n",
    "STOPPING_LEVEL = [3, 4, 5, 6]\n",
    "CLOSING_LEVEL = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "THRESHOLD = [200, 400, 600, 800, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def of2_model (data, OF_LIMIT, STOP_LOSS_LEVEL, CLOSING_LEVEL):\n",
    "    \n",
    "    # Prepare initial data for manipulation\n",
    "    df = init_of2_data(data)\n",
    "    stopping_amount = STOP_LOSS_LEVEL * TICK_SIZE\n",
    "    closing_amount = CLOSING_LEVEL * TICK_SIZE\n",
    "    \n",
    "    # Add signals [-1 : Sell, 0: None, 1: Buy]\n",
    "    df['signal'] = df['orderFlow'].apply(lambda x : -1 if (abs(x) > OF_LIMIT and x > 0) else (1 if (abs(x) > OF_LIMIT and x < 0) else 0))\n",
    "\n",
    "    # Add order signals [-1 : Sell, 0: None, 1: Buy]\n",
    "    \n",
    "    # Initialise order signals column\n",
    "    df['order'] = 0\n",
    "    i = 0 # counter\n",
    "    while i < len(df):\n",
    "    \n",
    "        # Current row's signal\n",
    "        curr_signal = df['signal'].iloc[i]\n",
    "\n",
    "        # Check if current row's signal is not 0, else do nothing\n",
    "        if curr_signal != 0:\n",
    "            \n",
    "            df['order'].iloc[i] = curr_signal\n",
    "            \n",
    "            if curr_signal > 0:\n",
    "                curr_sig_type = 'bid'\n",
    "                fwd_sig_type = 'ask'\n",
    "            else:\n",
    "                curr_sig_type = 'ask'\n",
    "                fwd_sig_type = 'bid'\n",
    "            \n",
    "            curr_px = df[curr_sig_type].iloc[i]\n",
    "            \n",
    "            if curr_signal > 0:\n",
    "                stop_px = curr_px - stopping_amount\n",
    "                close_px = curr_px + closing_amount\n",
    "            else:\n",
    "                stop_px = curr_px + stopping_amount\n",
    "                close_px = curr_px - closing_amount\n",
    "            \n",
    "            # Counter for forward tracking\n",
    "            j = i + 1\n",
    "            \n",
    "            while j < len(df):\n",
    "                \n",
    "                forward_row = df.iloc[j, :]\n",
    "                px = forward_row[fwd_sig_type]\n",
    "                \n",
    "                # Close position at the end of the day\n",
    "#                 if j < len(df) - 1:\n",
    "#                     if (pd.to_datetime(df.iloc[j + 1, :].name) - pd.to_datetime(forward_row.name)) > pd.Timedelta('5 min'):\n",
    "#                         if curr_signal > 0:\n",
    "#                             df['order'].iloc[j] = -1\n",
    "#                         else:\n",
    "#                             df['order'].iloc[j] = 1\n",
    "#                         j += 1\n",
    "#                         break\n",
    "#                 else:\n",
    "#                     if curr_signal > 0:\n",
    "#                         df['order'].iloc[j] = -1\n",
    "#                     else:\n",
    "#                         df['order'].iloc[j] = 1\n",
    "#                     j += 1\n",
    "#                     break\n",
    "                    \n",
    "                # Long position\n",
    "                if curr_signal > 0:\n",
    "                    # Check if past closing position level\n",
    "                    if px >= close_px:\n",
    "                        df['order'].iloc[j] = -1\n",
    "                        break\n",
    "                    elif px <= stop_px:\n",
    "                        df['order'].iloc[j] = -1\n",
    "                        break\n",
    "                    else:\n",
    "                        j += 1\n",
    "                    \n",
    "                # Short position\n",
    "                else:\n",
    "                    # Check if past closing position level\n",
    "                    if px <= close_px:\n",
    "                        df['order'].iloc[j] = 1\n",
    "                        break\n",
    "                    elif px >= stop_px:\n",
    "                        df['order'].iloc[j] = 1\n",
    "                        break\n",
    "                    else:\n",
    "                        j += 1\n",
    "            i = j + 1\n",
    "                    \n",
    "        else:\n",
    "            i += 1\n",
    "        \n",
    "    df['transaction'] = df.apply(lambda x: x['bid'] * -1 if x['order'] > 0 else (x['ask'] if x['order'] < 0 else 0), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "of2_results_df = pd.DataFrame(columns=['Stopping Loss Level', 'Closing Level', 'Threshold', 'Winning Probability', 'Reward to Risk', 'T-Stat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stoploss: 3 | Closing: 1 | Threshold: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louis/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stoploss: 3 | Closing: 2 | Threshold: 200\n",
      "Stoploss: 3 | Closing: 3 | Threshold: 200\n",
      "Stoploss: 3 | Closing: 4 | Threshold: 200\n",
      "Stoploss: 4 | Closing: 1 | Threshold: 200\n",
      "Stoploss: 4 | Closing: 2 | Threshold: 200\n",
      "Stoploss: 4 | Closing: 3 | Threshold: 200\n",
      "Stoploss: 4 | Closing: 4 | Threshold: 200\n",
      "Stoploss: 5 | Closing: 1 | Threshold: 200\n",
      "Stoploss: 5 | Closing: 2 | Threshold: 200\n",
      "Stoploss: 5 | Closing: 3 | Threshold: 200\n",
      "Stoploss: 5 | Closing: 4 | Threshold: 200\n",
      "Stoploss: 6 | Closing: 1 | Threshold: 200\n",
      "Stoploss: 6 | Closing: 2 | Threshold: 200\n",
      "Stoploss: 6 | Closing: 3 | Threshold: 200\n",
      "Stoploss: 6 | Closing: 4 | Threshold: 200\n",
      "Stoploss: 3 | Closing: 1 | Threshold: 400\n",
      "Stoploss: 3 | Closing: 2 | Threshold: 400\n",
      "Stoploss: 3 | Closing: 3 | Threshold: 400\n",
      "Stoploss: 3 | Closing: 4 | Threshold: 400\n",
      "Stoploss: 4 | Closing: 1 | Threshold: 400\n",
      "Stoploss: 4 | Closing: 2 | Threshold: 400\n",
      "Stoploss: 4 | Closing: 3 | Threshold: 400\n",
      "Stoploss: 4 | Closing: 4 | Threshold: 400\n",
      "Stoploss: 5 | Closing: 1 | Threshold: 400\n",
      "Stoploss: 5 | Closing: 2 | Threshold: 400\n",
      "Stoploss: 5 | Closing: 3 | Threshold: 400\n",
      "Stoploss: 5 | Closing: 4 | Threshold: 400\n",
      "Stoploss: 6 | Closing: 1 | Threshold: 400\n",
      "Stoploss: 6 | Closing: 2 | Threshold: 400\n",
      "Stoploss: 6 | Closing: 3 | Threshold: 400\n",
      "Stoploss: 6 | Closing: 4 | Threshold: 400\n",
      "Stoploss: 3 | Closing: 1 | Threshold: 600\n",
      "Stoploss: 3 | Closing: 2 | Threshold: 600\n",
      "Stoploss: 3 | Closing: 3 | Threshold: 600\n",
      "Stoploss: 3 | Closing: 4 | Threshold: 600\n",
      "Stoploss: 4 | Closing: 1 | Threshold: 600\n",
      "Stoploss: 4 | Closing: 2 | Threshold: 600\n",
      "Stoploss: 4 | Closing: 3 | Threshold: 600\n",
      "Stoploss: 4 | Closing: 4 | Threshold: 600\n",
      "Stoploss: 5 | Closing: 1 | Threshold: 600\n",
      "Stoploss: 5 | Closing: 2 | Threshold: 600\n",
      "Stoploss: 5 | Closing: 3 | Threshold: 600\n",
      "Stoploss: 5 | Closing: 4 | Threshold: 600\n",
      "Stoploss: 6 | Closing: 1 | Threshold: 600\n",
      "Stoploss: 6 | Closing: 2 | Threshold: 600\n",
      "Stoploss: 6 | Closing: 3 | Threshold: 600\n",
      "Stoploss: 6 | Closing: 4 | Threshold: 600\n",
      "Stoploss: 3 | Closing: 1 | Threshold: 800\n",
      "Stoploss: 3 | Closing: 2 | Threshold: 800\n",
      "Stoploss: 3 | Closing: 3 | Threshold: 800\n",
      "Stoploss: 3 | Closing: 4 | Threshold: 800\n",
      "Stoploss: 4 | Closing: 1 | Threshold: 800\n",
      "Stoploss: 4 | Closing: 2 | Threshold: 800\n",
      "Stoploss: 4 | Closing: 3 | Threshold: 800\n",
      "Stoploss: 4 | Closing: 4 | Threshold: 800\n",
      "Stoploss: 5 | Closing: 1 | Threshold: 800\n",
      "Stoploss: 5 | Closing: 2 | Threshold: 800\n",
      "Stoploss: 5 | Closing: 3 | Threshold: 800\n",
      "Stoploss: 5 | Closing: 4 | Threshold: 800\n",
      "Stoploss: 6 | Closing: 1 | Threshold: 800\n",
      "Stoploss: 6 | Closing: 2 | Threshold: 800\n",
      "Stoploss: 6 | Closing: 3 | Threshold: 800\n",
      "Stoploss: 6 | Closing: 4 | Threshold: 800\n",
      "Stoploss: 3 | Closing: 1 | Threshold: 1000\n",
      "Stoploss: 3 | Closing: 2 | Threshold: 1000\n",
      "Stoploss: 3 | Closing: 3 | Threshold: 1000\n",
      "Stoploss: 3 | Closing: 4 | Threshold: 1000\n",
      "Stoploss: 4 | Closing: 1 | Threshold: 1000\n",
      "Stoploss: 4 | Closing: 2 | Threshold: 1000\n",
      "Stoploss: 4 | Closing: 3 | Threshold: 1000\n",
      "Stoploss: 4 | Closing: 4 | Threshold: 1000\n",
      "Stoploss: 5 | Closing: 1 | Threshold: 1000\n",
      "Stoploss: 5 | Closing: 2 | Threshold: 1000\n",
      "Stoploss: 5 | Closing: 3 | Threshold: 1000\n",
      "Stoploss: 5 | Closing: 4 | Threshold: 1000\n",
      "Stoploss: 6 | Closing: 1 | Threshold: 1000\n",
      "Stoploss: 6 | Closing: 2 | Threshold: 1000\n",
      "Stoploss: 6 | Closing: 3 | Threshold: 1000\n",
      "Stoploss: 6 | Closing: 4 | Threshold: 1000\n"
     ]
    }
   ],
   "source": [
    "for of_limit in THRESHOLD:\n",
    "    for stop in STOPPING_LEVEL:\n",
    "        for close in CLOSING_LEVEL:\n",
    "            print(f'Stoploss: { stop } | Closing: { close } | Threshold: { of_limit }')\n",
    "            transactions = of2_model(train_data, of_limit, stop, close)['transaction']\n",
    "            positions = [x for x in transactions if x != 0]\n",
    "            pnl = []\n",
    "            for i in range(0, len(positions), 2):\n",
    "                pos = (positions[i] + positions[i + 1]) * MULTIPLIER - 2 * COMMISSION\n",
    "                pnl.append(pos)\n",
    "            wp = winning_probability(pnl)\n",
    "            rr = reward_to_risk_ratio(pnl)\n",
    "            ts = t_stat(pnl)\n",
    "            of2_results_df.loc[len(of2_results_df)] = [stop, close, of_limit, wp, rr, ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "of2_results_df.to_csv('OF2_MODEL_RESULTS_APPENDED.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louis/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNL: 13103.699999999886 | Number of Closed Positions: 939 | Winning Probability: 0.9403620873269436 | Reward to Risk Ratio: 0.34558732261288083 | T-Statistic: 12.71696214669417\n"
     ]
    }
   ],
   "source": [
    "# Based on top T-statistic performance\n",
    "\n",
    "# Change with optimised training results\n",
    "of_limit = 200\n",
    "stop = 3\n",
    "close = 1\n",
    "\n",
    "transactions = of2_model(test_data, of_limit, stop, close)['transaction']\n",
    "positions = [x for x in transactions if x != 0]\n",
    "pnl = []\n",
    "for i in range(0, len(positions), 2):\n",
    "    pos = (positions[i] + positions[i + 1]) * MULTIPLIER - 2 * COMMISSION\n",
    "    pnl.append(pos)\n",
    "wp = winning_probability(pnl)\n",
    "rr = reward_to_risk_ratio(pnl)\n",
    "ts = t_stat(pnl)\n",
    "\n",
    "print(f'PNL: { sum(pnl) } | Number of Closed Positions: { len(pnl) } | Winning Probability: { wp } | Reward to Risk Ratio: { rr } | T-Statistic: { ts }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louis/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNL: 7454.300000000053 | Number of Closed Positions: 321 | Winning Probability: 0.40809968847352024 | Reward to Risk Ratio: 2.25733646015299 | T-Statistic: 2.1902812757391104\n"
     ]
    }
   ],
   "source": [
    "# Based on top Reward-to-Risk Ratio with at least T-stat of 2\n",
    "\n",
    "# Change with optimised training results\n",
    "of_limit = 200\n",
    "stop = 3\n",
    "close = 8\n",
    "\n",
    "transactions = of2_model(test_data, of_limit, stop, close)['transaction']\n",
    "positions = [x for x in transactions if x != 0]\n",
    "pnl = []\n",
    "for i in range(0, len(positions), 2):\n",
    "    pos = (positions[i] + positions[i + 1]) * MULTIPLIER - 2 * COMMISSION\n",
    "    pnl.append(pos)\n",
    "wp = winning_probability(pnl)\n",
    "rr = reward_to_risk_ratio(pnl)\n",
    "ts = t_stat(pnl)\n",
    "\n",
    "print(f'PNL: { sum(pnl) } | Number of Closed Positions: { len(pnl) } | Winning Probability: { wp } | Reward to Risk Ratio: { rr } | T-Statistic: { ts }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louis/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNL: 12182.399999999936 | Number of Closed Positions: 878 | Winning Probability: 0.9635535307517085 | Reward to Risk Ratio: 0.16792472312378987 | T-Statistic: 9.542513039720875\n"
     ]
    }
   ],
   "source": [
    "# Based on top Winning Probability with at least T-stat of 2\n",
    "\n",
    "# Change with optimised training results\n",
    "of_limit = 200\n",
    "stop = 6\n",
    "close = 1\n",
    "\n",
    "transactions = of2_model(test_data, of_limit, stop, close)['transaction']\n",
    "positions = [x for x in transactions if x != 0]\n",
    "pnl = []\n",
    "for i in range(0, len(positions), 2):\n",
    "    pos = (positions[i] + positions[i + 1]) * MULTIPLIER - 2 * COMMISSION\n",
    "    pnl.append(pos)\n",
    "wp = winning_probability(pnl)\n",
    "rr = reward_to_risk_ratio(pnl)\n",
    "ts = t_stat(pnl)\n",
    "\n",
    "print(f'PNL: { sum(pnl) } | Number of Closed Positions: { len(pnl) } | Winning Probability: { wp } | Reward to Risk Ratio: { rr } | T-Statistic: { ts }')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
